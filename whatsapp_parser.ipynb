{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c11b3b7",
   "metadata": {},
   "source": [
    "# WhatsApp Chat Parser\n",
    "\n",
    "This notebook parses WhatsApp chat export files and converts them into a structured pandas DataFrame for analysis.\n",
    "\n",
    "The chat format follows this pattern:\n",
    "```\n",
    "[DD/MM/YYYY, HH:MM:SS AM/PM] Username: Message text\n",
    "```\n",
    "\n",
    "Messages can span multiple lines, with new messages starting when a line begins with `[`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07703e7",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import pandas, datetime, re, and other necessary libraries for text processing and data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6639589",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "This notebook uses a YAML configuration file (`config.yml`) to manage file paths and settings:\n",
    "\n",
    "- **Data files** are stored in the `data/` folder\n",
    "- **Input file**: `data/_chat.txt` (your WhatsApp chat export)\n",
    "- **Output file**: `data/whatsapp_parsed_data.csv` (parsed DataFrame)\n",
    "- **Configuration**: `config.yml` (file paths and parsing settings in YAML format)\n",
    "\n",
    "Make sure your WhatsApp chat file is placed in the `data/` folder before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df471bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Load configuration from YAML file\n",
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Create convenient variables for file paths\n",
    "DATA_FOLDER = config['data']['folder']\n",
    "CHAT_FILE_NAME = config['data']['chat_file_name']\n",
    "OUTPUT_FILE_NAME = config['data']['output_file_name']\n",
    "CHAT_FILE_PATH = os.path.join(DATA_FOLDER, CHAT_FILE_NAME)\n",
    "OUTPUT_FILE_PATH = os.path.join(DATA_FOLDER, OUTPUT_FILE_NAME)\n",
    "\n",
    "# Create data folder if it doesn't exist\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10be8dd",
   "metadata": {},
   "source": [
    "## 2. Define Text Parsing Functions\n",
    "\n",
    "Create helper functions to parse WhatsApp message format, extract timestamps, usernames, and handle multi-line messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_whatsapp_line(line):\n",
    "    \"\"\"\n",
    "    Parse a WhatsApp message line and extract components.\n",
    "    Returns: (date_str, time_str, user, message) or None if not a valid message line\n",
    "    \"\"\"\n",
    "    # Clean the line first - remove any invisible characters and normalize whitespace\n",
    "    line = line.strip()\n",
    "    \n",
    "    # More flexible pattern to handle variations in spacing and formatting\n",
    "    # This pattern allows for:\n",
    "    # - Optional extra spaces\n",
    "    # - Different date formats (handles single or double digits)\n",
    "    # - More flexible username matching\n",
    "    pattern = r'^\\[\\s*(\\d{1,2}/\\d{1,2}/\\d{4})\\s*,\\s*(\\d{1,2}:\\d{2}:\\d{2}\\s*(?:AM|PM))\\s*\\]\\s*([^:]+?):\\s*(.*)$'\n",
    "    \n",
    "    match = re.match(pattern, line, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        date_str, time_str, user, message = match.groups()\n",
    "        return date_str.strip(), time_str.strip(), user.strip(), message.strip()\n",
    "    \n",
    "    # If the main pattern doesn't work, try a simpler fallback pattern\n",
    "    # This handles cases where there might be formatting issues\n",
    "    fallback_pattern = r'^\\[([^\\]]+)\\]\\s*([^:]+):\\s*(.*)$'\n",
    "    fallback_match = re.match(fallback_pattern, line)\n",
    "    \n",
    "    if fallback_match:\n",
    "        datetime_part, user, message = fallback_match.groups()\n",
    "        # Try to split the datetime part\n",
    "        if ', ' in datetime_part:\n",
    "            date_str, time_str = datetime_part.split(', ', 1)\n",
    "            return date_str.strip(), time_str.strip(), user.strip(), message.strip()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def is_message_start(line):\n",
    "    \"\"\"\n",
    "    Check if a line is the start of a new message (begins with '[')\n",
    "    \"\"\"\n",
    "    return line.strip().startswith('[')\n",
    "\n",
    "def parse_datetime_components(date_str, time_str):\n",
    "    \"\"\"\n",
    "    Parse date and time strings to extract individual components\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse date: DD/MM/YYYY (handle both single and double digit days/months)\n",
    "        date_parts = date_str.split('/')\n",
    "        if len(date_parts) != 3:\n",
    "            return None, None, None, None, None\n",
    "            \n",
    "        day, month, year = map(int, date_parts)\n",
    "        \n",
    "        # Create datetime object to get day of week\n",
    "        dt = datetime(year, month, day)\n",
    "        day_of_week = dt.strftime('%A')  # Full day name (e.g., 'Monday')\n",
    "        \n",
    "        return day_of_week, day, month, year, time_str\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing date/time: {date_str}, {time_str} - {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "print(\"Parsing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db484df",
   "metadata": {},
   "source": [
    "## 3. Read and Parse Chat File\n",
    "\n",
    "Read the chat text file and implement logic to identify message boundaries using the '[' character pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chat file path from config\n",
    "chat_file_path = CHAT_FILE_PATH\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(chat_file_path):\n",
    "    print(f\"File not found: {chat_file_path}\")\n",
    "    print(f\"Please make sure the file '{CHAT_FILE_NAME}' is in the '{DATA_FOLDER}' directory.\")\n",
    "else:\n",
    "    print(f\"Found chat file: {chat_file_path}\")\n",
    "    \n",
    "    # Read the file and parse messages\n",
    "    messages = []\n",
    "    current_message = None\n",
    "    parse_errors = 0\n",
    "    \n",
    "    with open(chat_file_path, 'r', encoding=config['parsing']['encoding']) as file:\n",
    "        for line_num, line in enumerate(file, 1):\n",
    "            line = line.rstrip('\\n\\r')  # Remove newline characters\n",
    "            \n",
    "            if is_message_start(line):\n",
    "                # Save previous message if exists\n",
    "                if current_message is not None:\n",
    "                    messages.append(current_message)\n",
    "                \n",
    "                # Parse new message\n",
    "                parsed = parse_whatsapp_line(line)\n",
    "                \n",
    "                if parsed:\n",
    "                    date_str, time_str, user, message = parsed\n",
    "                    current_message = {\n",
    "                        'date_str': date_str,\n",
    "                        'time_str': time_str,\n",
    "                        'user': user,\n",
    "                        'message': message,\n",
    "                        'line_num': line_num\n",
    "                    }\n",
    "                else:\n",
    "                    parse_errors += 1\n",
    "                    if parse_errors <= 5:  # Show only first 5 errors to avoid spam\n",
    "                        print(f\"Warning: Could not parse line {line_num}: {line[:100]}...\")\n",
    "                    current_message = None\n",
    "            else:\n",
    "                # This is a continuation of the previous message\n",
    "                if current_message is not None:\n",
    "                    current_message['message'] += '\\n' + line\n",
    "        \n",
    "        # Don't forget the last message\n",
    "        if current_message is not None:\n",
    "            messages.append(current_message)\n",
    "    \n",
    "    print(f\"Successfully parsed {len(messages)} messages from the chat file.\")\n",
    "    if parse_errors > 0:\n",
    "        print(f\"Total parsing errors: {parse_errors}\")\n",
    "    \n",
    "    # Display a few sample messages\n",
    "    if messages:\n",
    "        print(\"\\nSample messages:\")\n",
    "        for i, msg in enumerate(messages[:config['parsing']['max_sample_messages']]):\n",
    "            print(f\"Message {i+1}:\")\n",
    "            print(f\"  Date: {msg['date_str']}\")\n",
    "            print(f\"  Time: {msg['time_str']}\")\n",
    "            print(f\"  User: {msg['user']}\")\n",
    "            max_length = config['parsing']['max_display_message_length']\n",
    "            print(f\"  Message: {msg['message'][:max_length]}{'...' if len(msg['message']) > max_length else ''}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No messages were successfully parsed. Please check the file format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76b392",
   "metadata": {},
   "source": [
    "## 4. Clean and Process Data\n",
    "\n",
    "Clean the extracted data, handle special characters, and process multi-line messages by concatenating them properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message_text(text):\n",
    "    \"\"\"\n",
    "    Clean message text by handling special characters and formatting\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove extra whitespace while preserving intentional line breaks\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def clean_username(username):\n",
    "    \"\"\"\n",
    "    Clean and standardize usernames\n",
    "    \"\"\"\n",
    "    # Remove any extra whitespace\n",
    "    username = username.strip()\n",
    "    \n",
    "    # Handle any special characters or formatting issues\n",
    "    return username\n",
    "\n",
    "# Clean the parsed messages\n",
    "cleaned_messages = []\n",
    "\n",
    "for msg in messages:\n",
    "    cleaned_msg = {\n",
    "        'date_str': msg['date_str'],\n",
    "        'time_str': msg['time_str'],\n",
    "        'user': clean_username(msg['user']),\n",
    "        'message': clean_message_text(msg['message']),\n",
    "        'line_num': msg['line_num']\n",
    "    }\n",
    "    cleaned_messages.append(cleaned_msg)\n",
    "\n",
    "print(f\"Cleaned {len(cleaned_messages)} messages.\")\n",
    "\n",
    "# Check for unique users\n",
    "unique_users = set(msg['user'] for msg in cleaned_messages)\n",
    "print(f\"Unique users found: {list(unique_users)}\")\n",
    "\n",
    "# Show some statistics\n",
    "total_chars = sum(len(msg['message']) for msg in cleaned_messages)\n",
    "avg_message_length = total_chars / len(cleaned_messages) if cleaned_messages else 0\n",
    "\n",
    "print(f\"Total characters in all messages: {total_chars:,}\")\n",
    "print(f\"Average message length: {avg_message_length:.1f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183e66c",
   "metadata": {},
   "source": [
    "## 5. Extract Date and Time Components\n",
    "\n",
    "Parse the date and time strings to extract Day of Week, Day, Month, Year, and Time components using datetime functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each message to extract date and time components\n",
    "processed_data = []\n",
    "\n",
    "for msg in cleaned_messages:\n",
    "    day_of_week, day, month, year, time = parse_datetime_components(\n",
    "        msg['date_str'], msg['time_str']\n",
    "    )\n",
    "    \n",
    "    if day_of_week is not None:  # Successfully parsed\n",
    "        processed_data.append({\n",
    "            'DoW': day_of_week,\n",
    "            'Day': day,\n",
    "            'Month': month,\n",
    "            'Year': year,\n",
    "            'Time': time,\n",
    "            'User': msg['user'],\n",
    "            'text_message': msg['message']\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Warning: Could not parse date/time for message at line {msg['line_num']}\")\n",
    "\n",
    "print(f\"Successfully processed {len(processed_data)} messages with date/time components.\")\n",
    "\n",
    "# Show some examples of the processed data\n",
    "if processed_data:\n",
    "    print(\"\\nSample processed data:\")\n",
    "    for i, data in enumerate(processed_data[:3]):\n",
    "        print(f\"Record {i+1}:\")\n",
    "        for key, value in data.items():\n",
    "            if key == 'text_message':\n",
    "                display_text = value[:50] + '...' if len(value) > 50 else value\n",
    "                print(f\"  {key}: {display_text}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad0508",
   "metadata": {},
   "source": [
    "## 6. Create Final DataFrame\n",
    "\n",
    "Construct the pandas DataFrame with columns: Day of Week, Day, Month, Year, Time, User, and text_message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c26929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Ensure the columns are in the correct order\n",
    "column_order = ['DoW', 'Day', 'Month', 'Year', 'Time', 'User', 'text_message']\n",
    "df = df[column_order]\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(\"DataFrame created successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Show the first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Show data types\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e073313",
   "metadata": {},
   "source": [
    "## 7. Data Validation and Preview\n",
    "\n",
    "Validate the parsed data, check for any parsing errors, and display sample rows and basic statistics of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fdcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation and statistics\n",
    "print(\"=== DATA VALIDATION ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print()\n",
    "\n",
    "# Check unique users\n",
    "print(\"Unique users:\")\n",
    "print(df['User'].value_counts())\n",
    "print()\n",
    "\n",
    "# Check date range\n",
    "print(\"Date range:\")\n",
    "print(f\"Years: {sorted(df['Year'].unique())}\")\n",
    "print(f\"Months: {sorted(df['Month'].unique())}\")\n",
    "print()\n",
    "\n",
    "# Message statistics\n",
    "print(\"=== MESSAGE STATISTICS ===\")\n",
    "print(f\"Total messages: {len(df):,}\")\n",
    "print(f\"Messages per user:\")\n",
    "user_counts = df['User'].value_counts()\n",
    "for user, count in user_counts.items():\n",
    "    print(f\"  {user}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Text length statistics\n",
    "df['message_length'] = df['text_message'].str.len()\n",
    "print(\"Message length statistics:\")\n",
    "print(f\"  Average: {df['message_length'].mean():.1f} characters\")\n",
    "print(f\"  Median: {df['message_length'].median():.1f} characters\")\n",
    "print(f\"  Max: {df['message_length'].max():,} characters\")\n",
    "print(f\"  Min: {df['message_length'].min()} characters\")\n",
    "print()\n",
    "\n",
    "# Day of week distribution\n",
    "print(\"Messages by day of week:\")\n",
    "day_counts = df['DoW'].value_counts()\n",
    "# Sort by day of week order\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for day in day_order:\n",
    "    if day in day_counts:\n",
    "        count = day_counts[day]\n",
    "        print(f\"  {day}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Sample of longest and shortest messages\n",
    "print(\"\\n=== SAMPLE MESSAGES ===\")\n",
    "print(\"Longest message:\")\n",
    "longest_idx = df['message_length'].idxmax()\n",
    "longest_msg = df.loc[longest_idx]\n",
    "print(f\"User: {longest_msg['User']}\")\n",
    "print(f\"Date: {longest_msg['Day']}/{longest_msg['Month']}/{longest_msg['Year']}\")\n",
    "print(f\"Length: {longest_msg['message_length']} characters\")\n",
    "print(f\"Message: {longest_msg['text_message'][:200]}{'...' if len(longest_msg['text_message']) > 200 else ''}\")\n",
    "print()\n",
    "\n",
    "print(\"Shortest non-empty message:\")\n",
    "non_empty = df[df['message_length'] > 0]\n",
    "if not non_empty.empty:\n",
    "    shortest_idx = non_empty['message_length'].idxmin()\n",
    "    shortest_msg = df.loc[shortest_idx]\n",
    "    print(f\"User: {shortest_msg['User']}\")\n",
    "    print(f\"Date: {shortest_msg['Day']}/{shortest_msg['Month']}/{shortest_msg['Year']}\")\n",
    "    print(f\"Length: {shortest_msg['message_length']} characters\")\n",
    "    print(f\"Message: '{shortest_msg['text_message']}'\")\n",
    "\n",
    "# Drop the temporary column\n",
    "df = df.drop('message_length', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to CSV for further analysis using config path\n",
    "output_filename = OUTPUT_FILE_PATH\n",
    "df.to_csv(output_filename, index=False, encoding=config['parsing']['encoding'])\n",
    "print(f\"DataFrame saved to: {output_filename}\")\n",
    "\n",
    "# Display final DataFrame info\n",
    "print(f\"\\nFinal DataFrame shape: {df.shape}\")\n",
    "print(\"Ready for analysis!\")\n",
    "\n",
    "# Show a sample of the final data\n",
    "print(\"\\nSample of final data:\")\n",
    "print(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
